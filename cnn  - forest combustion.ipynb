{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model =Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim=128,init='uniform',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=2, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim=2,activation='softmax',init='uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140 images belonging to 2 classes.\n",
      "Found 60 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r'C:\\Users\\mahit\\OneDrive\\Desktop\\AI intern proj1\\forest combustion\\trainset',target_size = (64,64),batch_size = 32,class_mode = 'categorical')\n",
    "x_test = test_datagen.flow_from_directory(r'C:\\Users\\mahit\\OneDrive\\Desktop\\AI intern proj1\\forest combustion\\testset',target_size = (64,64),batch_size = 32,class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'forestwithfire': 0, 'forestwithoutfire': 1}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',optimizer = \"adam\",metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\mahit\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.6891 - acc: 0.5558 - val_loss: 0.6626 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.5135 - acc: 0.7226 - val_loss: 0.4498 - val_acc: 0.7000\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 4s 823ms/step - loss: 0.3830 - acc: 0.8336 - val_loss: 0.2663 - val_acc: 0.9333\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 5s 930ms/step - loss: 0.2602 - acc: 0.9337 - val_loss: 0.1903 - val_acc: 0.9333\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 5s 933ms/step - loss: 0.2179 - acc: 0.9104 - val_loss: 0.3045 - val_acc: 0.8833\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 4s 817ms/step - loss: 0.2892 - acc: 0.8524 - val_loss: 0.1532 - val_acc: 0.9333\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 4s 806ms/step - loss: 0.1636 - acc: 0.9552 - val_loss: 0.1915 - val_acc: 0.9167\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.1468 - acc: 0.9424 - val_loss: 0.1719 - val_acc: 0.9333\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 4s 874ms/step - loss: 0.1329 - acc: 0.9465 - val_loss: 0.1955 - val_acc: 0.9167\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.1585 - acc: 0.9250 - val_loss: 0.2046 - val_acc: 0.9000\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.1488 - acc: 0.9424 - val_loss: 0.2708 - val_acc: 0.9333\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 4s 896ms/step - loss: 0.1736 - acc: 0.9187 - val_loss: 0.2437 - val_acc: 0.8833\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.1924 - acc: 0.9123 - val_loss: 0.1265 - val_acc: 0.9500\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 4s 804ms/step - loss: 0.1355 - acc: 0.9616 - val_loss: 0.1275 - val_acc: 0.9500\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 4s 880ms/step - loss: 0.0879 - acc: 0.9808 - val_loss: 0.1540 - val_acc: 0.9333\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.0917 - acc: 0.9680 - val_loss: 0.1346 - val_acc: 0.9333\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 5s 911ms/step - loss: 0.0830 - acc: 0.9680 - val_loss: 0.2782 - val_acc: 0.8667\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 4s 871ms/step - loss: 0.0913 - acc: 0.9616 - val_loss: 0.1366 - val_acc: 0.9333\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.0768 - acc: 0.9680 - val_loss: 0.3592 - val_acc: 0.8333\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.0875 - acc: 0.9680 - val_loss: 0.2224 - val_acc: 0.9333\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 4s 865ms/step - loss: 0.1043 - acc: 0.9680 - val_loss: 0.2628 - val_acc: 0.8833\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 4s 897ms/step - loss: 0.0808 - acc: 0.9593 - val_loss: 0.1469 - val_acc: 0.9333\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 4s 792ms/step - loss: 0.0670 - acc: 0.9808 - val_loss: 0.2090 - val_acc: 0.9167\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 4s 773ms/step - loss: 0.0564 - acc: 0.9849 - val_loss: 0.1323 - val_acc: 0.9500\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 4s 776ms/step - loss: 0.0485 - acc: 0.9744 - val_loss: 0.1312 - val_acc: 0.9500\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 4s 848ms/step - loss: 0.0366 - acc: 0.9936 - val_loss: 0.1408 - val_acc: 0.9333\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.0349 - acc: 0.9872 - val_loss: 0.1312 - val_acc: 0.9500\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 4s 773ms/step - loss: 0.0436 - acc: 0.9936 - val_loss: 0.2233 - val_acc: 0.9167\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 4s 883ms/step - loss: 0.0534 - acc: 0.9849 - val_loss: 0.1263 - val_acc: 0.9500\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 4s 873ms/step - loss: 0.0391 - acc: 0.9936 - val_loss: 0.1317 - val_acc: 0.9500\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 4s 883ms/step - loss: 0.0288 - acc: 0.9936 - val_loss: 0.1692 - val_acc: 0.9167\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 5s 907ms/step - loss: 0.0239 - acc: 0.9936 - val_loss: 0.1244 - val_acc: 0.9500\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 4s 834ms/step - loss: 0.0168 - acc: 0.9936 - val_loss: 0.1199 - val_acc: 0.9500\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 4s 867ms/step - loss: 0.0179 - acc: 1.0000 - val_loss: 0.1787 - val_acc: 0.9333\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 4s 862ms/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.1168 - val_acc: 0.9500\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.1673 - val_acc: 0.9333\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 5s 932ms/step - loss: 0.0155 - acc: 0.9936 - val_loss: 0.1147 - val_acc: 0.9500\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 4s 838ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.1475 - val_acc: 0.9333\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 4s 856ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.1174 - val_acc: 0.9500\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 4s 798ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.1276 - val_acc: 0.9667\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 4s 880ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.1240 - val_acc: 0.9667\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 4s 803ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.1519 - val_acc: 0.9333\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 4s 802ms/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.1322 - val_acc: 0.9500\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.1186 - val_acc: 0.9500\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 4s 877ms/step - loss: 0.0440 - acc: 0.9849 - val_loss: 0.1819 - val_acc: 0.9333\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 4s 835ms/step - loss: 0.2239 - acc: 0.9013 - val_loss: 0.1476 - val_acc: 0.9500\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 4s 821ms/step - loss: 0.2051 - acc: 0.9104 - val_loss: 1.2932 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 4s 816ms/step - loss: 0.2183 - acc: 0.8825 - val_loss: 0.3849 - val_acc: 0.9167\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 4s 881ms/step - loss: 0.1240 - acc: 0.9552 - val_loss: 0.6531 - val_acc: 0.8000\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 4s 889ms/step - loss: 0.0949 - acc: 0.9552 - val_loss: 0.1543 - val_acc: 0.9500\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 5s 908ms/step - loss: 0.0415 - acc: 0.9872 - val_loss: 0.1497 - val_acc: 0.9500\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 5s 961ms/step - loss: 0.0374 - acc: 0.9785 - val_loss: 0.2490 - val_acc: 0.9000\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 4s 892ms/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.1482 - val_acc: 0.9500\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.1268 - val_acc: 0.9500\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 4s 836ms/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.1295 - val_acc: 0.9667\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.1955 - val_acc: 0.9333\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 4s 808ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.1527 - val_acc: 0.9500\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 4s 793ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.1274 - val_acc: 0.9500\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 4s 778ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.1255 - val_acc: 0.9500\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 4s 888ms/step - loss: 0.0148 - acc: 0.9936 - val_loss: 0.1393 - val_acc: 0.9500\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 4s 799ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.2417 - val_acc: 0.9000\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 4s 782ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.1375 - val_acc: 0.9500\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 4s 787ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.1244 - val_acc: 0.9500\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 4s 882ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.1330 - val_acc: 0.9667\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 4s 776ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1837 - val_acc: 0.9333\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 4s 783ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1388 - val_acc: 0.9667\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 4s 827ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.1243 - val_acc: 0.9500\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 4s 880ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.1303 - val_acc: 0.9667\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 4s 779ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.1564 - val_acc: 0.9667\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1643 - val_acc: 0.9667\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1385 - val_acc: 0.9667\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 4s 850ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1279 - val_acc: 0.9500\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 4s 806ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1337 - val_acc: 0.9667\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1459 - val_acc: 0.9500\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 4s 813ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1349 - val_acc: 0.9667\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 4s 861ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1376 - val_acc: 0.9667\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1343 - val_acc: 0.9500\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 4s 783ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1323 - val_acc: 0.9500\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 4s 887ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1322 - val_acc: 0.9500\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 4s 829ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1315 - val_acc: 0.9500\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 4s 780ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1393 - val_acc: 0.9667\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 4s 809ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1503 - val_acc: 0.9667\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 4s 893ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1516 - val_acc: 0.9667\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 4s 887ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1379 - val_acc: 0.9667\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 4s 896ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1354 - val_acc: 0.9500\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 4s 860ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1450 - val_acc: 0.9667\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 4s 880ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1561 - val_acc: 0.9667\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 4s 873ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1518 - val_acc: 0.9833\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 4s 791ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1358 - val_acc: 0.9667\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 4s 853ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1311 - val_acc: 0.9500\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 4s 863ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1386 - val_acc: 0.9667\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 4s 815ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1470 - val_acc: 0.9833\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 4s 807ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.9667\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 4s 863ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1319 - val_acc: 0.9500\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 4s 829ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1308 - val_acc: 0.9500\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 4s 812ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 0.9667\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 4s 795ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1479 - val_acc: 0.9667\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 4s 859ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1429 - val_acc: 0.9667\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 4s 813ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1293 - val_acc: 0.9500\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1322 - val_acc: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1be16fe74c8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=5,epochs=100,validation_data=x_test,validation_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"forest1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6241354  0.37586457]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "model =load_model('forest1.h5')\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "from skimage.transform import resize\n",
    "def detect(frame):\n",
    "    try:\n",
    "        img= resize(frame,(64,64))\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "        if(np.max(img)>1):\n",
    "            img =img/255.0\n",
    "        prediction =model.predict(img)\n",
    "        print (prediction)\n",
    "        prediction_class = model.predict_classes(img)\n",
    "        print(prediction_class)\n",
    "        return prediction_class\n",
    "    except AttributeError:\n",
    "            print(\"shape not found\")\n",
    "frame= cv2.imread(r'C:\\Users\\mahit\\OneDrive\\Desktop\\AI intern proj1\\withfire.jpg')\n",
    "data= detect(frame)\n",
    "data\n",
    "from playsound import playsound\n",
    "if(data[0]==0):\n",
    "    playsound(r'C:\\Users\\mahit\\Downloads\\Tornado_Siren.mp3')\n",
    "#elif(data[0]==1):\n",
    "   # playsound(r'C:\\Users\\DELL\\Downloads\\Annoying_Alarm_Clock-UncleKornicob-1.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
